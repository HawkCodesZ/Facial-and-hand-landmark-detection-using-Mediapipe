
 
 	 
FACIAL AND HAND LANDMARK 
DETECTION USING MEDIAPIPE  
OPENCV 
 
Contents 
 
1.	Abstract 
 
2.	Introduction 
 
3.	Objectives 
 
4.	Methodology 
 
4.1.	MediaPipe 
4.2.	Facial Landmark Detection 
4.3.	Hand Landmark Detection 
4.4.	Source Code 
 
5.	Results 
 
5.1.	Facial Landmark Results 
5.2.	Hand Landmark Results 
 
6.	Applications 
 
6.1.	Face Landmark Applications 
6.2.	Hand Landmark Applications 
 
7.	Conclusion  
 
8.	Future Work 
 
8.1.	Real Time Applications 
8.2.	Customization 
8.3.	Integration with other technologies 
 
9.	References 
 
 
Facial and Hand Landmark Detection using 
MediaPipe  
1. Abstract 
 
This project delves into the integration and exploration of MediaPipe, a versatile 
opensource library developed by Google, to harness the capabilities of its facial and hand 
landmark detection models. The primary objectives were to leverage the facial landmark 
model for precise identification of key facial features and to implement hand landmark 
detection to localize crucial points on the hand. Through seamless integration of 
MediaPipe's Python APIs, the project successfully demonstrated the accurate marking of 
468 facial landmarks and 21 hand landmarks, showcasing the models' robustness in 
challenging conditions, including varying lighting and diverse poses. 
The facial landmark detection model provided a detailed representation of facial features, 
enabling real-time tracking of eye movements, mouth shape, and eyebrow positions. This 
opens avenues for applications such as emotion recognition, avatar animation, and facial 
authentication. The hand landmark detection model demonstrated precision in locating 
key points on the hand, facilitating applications like gesture recognition, interactive 
virtual interfaces, and augmented reality experiences. 
The results underscore the potential of facial and hand landmark detection in diverse 
domains. The accurate tracking of facial and hand features holds promise for 
humancomputer interaction, virtual reality, and augmented reality applications. The report 
outlines applications in emotion recognition, gaze tracking, gesture recognition, and 
virtual interfaces, showcasing the versatility of this technology. 
Looking forward, the project suggests avenues for future work, including optimizing the 
code for real-time applications, customizing the models for specific use cases, and 
exploring integration with other computer vision technologies for a more comprehensive 
solution. This abstract encapsulates the successful implementation and exploration of 
facial and hand landmark detection using MediaPipe, providing a foundation for further 
research and development in the dynamic field of computer vision. 
 
 
 
 
 
 
 
2.	Introduction: 
In recent years, advancements in computer vision have paved the way for innovative 
applications in human-computer interaction, virtual reality, and augmented reality. This 
project explores the capabilities of the MediaPipe library, specifically focusing on its 
facial and hand landmark detection models. Developed by Google, MediaPipe provides 
pretrained models that simplify implementing complex computer vision tasks. In this 
report, we delve into the integration of MediaPipe into our project and the subsequent use 
of its facial and hand landmark models. 
 
3.	Objectives: 
The main objectives of this work are twofold. First, we aim to harness the power of 
MediaPipe's facial landmark model to accurately identify key facial features. Secondly, 
we try to implement handwriting recognition using MediaPipe which allows the precise 
transfer of handwriting symbols. Beyond the technological applications, we aim to 
investigate how facial and gesture recognition can be applied in various industries. 
 
4.	Methodology: 
 
4.1	MediaPipe Integration: 
Integrating MediaPipe into our project proved to be a simple process, thanks to the 
welldocumented and easy-to-use Python API provided by the library this integration 
provided facial and hand logo recognition the capability integrated seamlessly into 
our computer vision application. 
 
4.2	Facial Landmark Detection: 
The facial landmark detection model in MediaPipe is a robust solution that identifies 
468 facial landmarks. These landmarks encompass key points around the eyes, nose, 
mouth, and face contours, offering a detailed representation of facial features. 
Leveraging this model allows for real-time tracking of eye movements, mouth shape, 
and eyebrow positions. 
 
 
4.3	Hand Landmark Detection: 
MediaPipe's hand landmark detection model locates 21 key points on the hand, 
including fingertips, knuckles, and the palm. The precision of this hand tracking is 
notable, making it suitable for applications such as gesture recognition, interactive 
virtual interfaces, and augmented reality experiences. 
 
4.4	Source Code: 
•	Installing the necessary libraries: 
  
•	Importing the needed libraries: 
 
  
?	OpenCV - for camera input 
?	MatPlotLib (Pyplot) - for plotting/graphical representation 
?	MediaPipe - for landmark detection 
 
•	Creating a detection function: 
 
  
 
The mediapipe model works on RGB images, but the camera input through 
OpenCV is in BGR format. So first we need to convert the image from BGR 
to RGB and make the image non-writable. Then we process the image through 
our model which will give us the results which we return in this function 
 
•	Picking our needed models from the MediaPipe library: 
 
  
 
We need the Holistic model for the landmark detection and the Drawing 
utilities for plotting the landmarks which we store in mp_holistic and 
mp_drawing variables respectively. 
 
 
 
 
•	Function to draw the landmarks: 
 
  
 
This function takes the image and the results from the detection function as its 
arguments and plots the landmarks for face, pose, left and right hands using 
the mp_drawing (Drawing utilities from MediaPipe) as mentioned above. 
 
•	Finally taking live feed as input from the camera and using our model: 
 
  
 
This code block here takes input from our device camera using OpenCV and 
stores it in variable 'cap'. We set the detection and tracking confidence as 0.5 
each to test our results. We call the 'mediapipe_detection' function which we 
declared before for the detection the result of which we pass to our 
'draw_styled_landmarks' function to plot the landmarks. Then we show the 
results in our window feed. We put a waitkey of 10 and set the breaking key to 
be 'q' which on being pressed will release the feed and destroy the created 
window. 
 
 
 
 
 
 
 
 
 
 
•	Plotting the result using MatPlotLib(optional): 
 
  
 
 
5.  Results 
The performance of the MediaPipe models in landmark detection was commendable. 
Even in challenging conditions, such as varying lighting and diverse poses, the models 
consistently and accurately marked facial and hand landmarks. The following subsections 
detail the results of facial and hand landmark detection. 
 
5.1 Facial Landmark Results 
The facial landmarks tracked by MediaPipe closely followed the contours of the face, 
capturing subtle facial expressions with high accuracy. This capability opens up avenues 
for applications such as emotion recognition, avatar animation, and facial authentication. 
Real-time tracking of these landmarks allows for dynamic interactions in virtual and 
augmented reality environments. 
  
 
  
 
 
 
 
 
5.2 Hand Landmark Results 
The hand landmark detection model excelled in providing precise coordinates for key 
points on the hand. This accuracy is crucial for applications like hand gesture 
recognition, enabling natural and intuitive interactions with devices. Additionally, the 
potential for creating virtual touch interfaces enhances user engagement in virtual 
reality environments. 
 
  
 
  
 
6.	Applications: 
 
6.1 Facial Landmark Applications 
 
Emotion Recognition 
Analyzing facial landmarks allows for effective emotion recognition. By tracking 
changes in facial features, the system can infer the user's emotional state. This has 
applications in human-computer interaction, where systems can adapt based on the 
user's emotional cues. 
 
Gaze Tracking 
MediaPipe's facial landmark detection includes points around the eyes, facilitating 
gaze tracking. Gaze tracking technology is essential for various applications, 
including attention monitoring in self-driving cars and user interface design. 
 
      6.2 Hand Landmark Applications 
 
Gesture Recognition 
The precise localization of hand landmarks enables accurate gesture recognition. This 
can be applied in gaming, virtual reality, and human-computer interaction, providing 
users with an intuitive means of control. 
 
Virtual Interfaces 
Hand landmarks can be utilized to create virtual touch interfaces, allowing users to 
interact with digital content in a tactile manner. This has implications for virtual 
reality applications and interactive displays. 
 
7.	Conclusion: 
The integration and exploration of MediaPipe's facial and hand landmark models have 
yielded promising results. The accurate detection of landmarks opens the door to a myriad 
of applications in human-computer interaction, virtual reality, and augmented reality. This 
project successfully implemented the models, showcasing their capabilities and laying the 
groundwork for further research and development in computer vision. 
 
8.	Future Work: 
As with any technology project, there are avenues for further improvement and exploration 
 
8.1 Real-time Applications 
Optimizing the code for real-time performance is crucial for applications requiring 
low latency. This involves fine-tuning the implementation to ensure that the landmark 
detection operates seamlessly in real-world, dynamic environments. 
 
8.2 Customization 
The possibility of training and fine-tuning the models for specific use cases is an 
exciting prospect. Customizing the models could enhance accuracy and allow for 
tailoring the technology to unique requirements in various industries. 
 
8.3 Integration with Other Technologies 
Exploring the integration of facial and hand landmark detection with other computer 
vision technologies can lead to a more comprehensive solution. This could involve 
combining landmark detection with object recognition or scene understanding for 
enhanced contextual understanding. 
 
9. References: 
 
•	MediaPipe GitHub Repository 
•	MediaPipe Documentation 
•	Cao, Z., Simon, T., Wei, S. E., & Sheikh, Y. (2014). Realtime Multi-Person 2D 
Pose Estimation using Part Affinity Fields. 
•	Sun, Y., Wang, X., & Tang, X. (2018). Deep hand pose estimation: a review. 
•	MediaPipe Model Documentation: 
Specific documentation for the facial landmark and hand landmark models 
within MediaPipe. 
•	Zhang, X., Yin, X., Zhang, S., Liu, Y., & Ouyang, W. (2018). Feature Pyramid 
Networks for Object Detection. 
•	Forsyth, D. A., & Ponce, J. (2011). Computer Vision: Algorithms and 
Applications. 
•	Saragih, J. M., Lucey, S., & Cohn, J. F. (2011). Deformable model fitting by 
regularized landmark mean-shift. 
•	Cootes, T. F., Edwards, G. J., & Taylor, C. J. (2001). Active appearance 
models. 
 
 
